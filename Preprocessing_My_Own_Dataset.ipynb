{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_json('labels.json')\n",
    "\n",
    "# converts label lists to strings and assigns them to the \"annotations\" column\n",
    "data['annotations'] = data['annotations'].apply(lambda x: ','.join(x))\n",
    "\n",
    "# extracting labels and converting them to numeric values\n",
    "encoder = LabelEncoder()\n",
    "numeric_labels = encoder.fit_transform(data['annotations'])\n",
    "\n",
    "# writing numerical labels to the \"labels\" column in the data frame\n",
    "data['labels'] = numeric_labels\n",
    "\n",
    "# removing the .jpg ending\n",
    "data['image'] = data['image'].str.replace('.jpg', '')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "folder_path = (r'C:\\Users\\ghost\\Desktop\\STUDIA\\Semestr\\ZPD\\Projekt\\Warzywa')\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg'):  # loading only files with .jpg extension\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = Image.open(image_path).convert('RGB') # use of RGB\n",
    "        image = image.resize((250, 250))  # required image size\n",
    "        image = np.array(image)  # transforming an image into a numpy array\n",
    "        image_list.append(image)\n",
    "        label_list.append(data.loc[data['image'] == os.path.splitext(filename)[0], 'labels'].iloc[0])  # assigning a label to an image\n",
    "\n",
    "image_array = np.array(image_list)  # converting a list of images to a numpy matrix\n",
    "label_array = np.array(label_list)  # converting a list of labels to a numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ilość obrazów: \", len(image_array))\n",
    "print(\"Ilość etykiet: \", len(label_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None 0, Broccoli 1, White onions 2, Red onions 3, Garlic 4, Carrots 5\n",
    "class_counts = np.bincount(label_array)\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# changing the shape of the input data matrix\n",
    "image_array_flat = image_array.reshape((image_array.shape[0], -1))\n",
    "\n",
    "# data standardization\n",
    "scaler = StandardScaler()\n",
    "image_array_scaled = scaler.fit_transform(image_array_flat)\n",
    "\n",
    "# changing the shape of the input data matrix back to the original one\n",
    "image_array_scaled = image_array_scaled.reshape((image_array.shape[0], 250, 250, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# definition of image generator\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,  # image rotation range in degrees\n",
    "        width_shift_range=0.2,  # horizontal displacement range\n",
    "        height_shift_range=0.2,  # vertical travel range\n",
    "        horizontal_flip=True,  # horizontal mirroring\n",
    "        vertical_flip=True)  # vertical mirroring\n",
    "\n",
    "# generator application\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "for image, label in zip(image_array, label_array):\n",
    "    augmented_images.append(image)\n",
    "    augmented_labels.append(label)\n",
    "    generated_images = 0\n",
    "    for batch in datagen.flow(np.expand_dims(image, axis=0), np.array([label]), batch_size=1):\n",
    "        augmented_images.append(batch[0])\n",
    "        augmented_labels.append(batch[1][0])\n",
    "        if len(augmented_images) >= 1:\n",
    "            break\n",
    "image_array_augmented = np.array(augmented_images)\n",
    "label_array_augmented = np.array(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None 0, Broccoli 1, White onions 2, Red onions 3, Garlic 4, Carrots 5\n",
    "class_counts_augmented = np.bincount(label_array_augmented)\n",
    "print(class_counts_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_s = 0.7 # percentage of training data\n",
    "val_s = 0.15  # percentage of validation data\n",
    "test_s = 0.15  # percentage of test data\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(image_array_augmented, label_array_augmented, test_size=test_s)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_s/(train_s+val_s))\n",
    "\n",
    "# Calculating the statistics for each set\n",
    "train_size = len(X_train)\n",
    "val_size = len(X_val)\n",
    "test_size = len(X_test)\n",
    "\n",
    "num_classes_train = len(np.unique(y_train))\n",
    "num_classes_val = len(np.unique(y_val))\n",
    "num_classes_test = len(np.unique(y_test))\n",
    "\n",
    "class_counts_train = np.bincount(y_train)\n",
    "class_counts_val = np.bincount(y_val)\n",
    "class_counts_test = np.bincount(y_test)\n",
    "\n",
    "class_proportions_train = class_counts_train / train_size\n",
    "class_proportions_val = class_counts_val / val_size\n",
    "class_proportions_test = class_counts_test / test_size\n",
    "\n",
    "# Displaying the results\n",
    "print(\"TRENING Dataset:\")\n",
    "print(\"Number of images:\", train_size)\n",
    "print(\"Number of classes:\", num_classes_train)\n",
    "print(\"Number of images from each class:\", class_counts_train)\n",
    "print(\"Class proportions:\", class_proportions_train)\n",
    "\n",
    "print(\"VALID Dataset:\")\n",
    "print(\"Number of images:\", val_size)\n",
    "print(\"Number of classes:\", num_classes_val)\n",
    "print(\"Number of images from each class:\", class_counts_val)\n",
    "print(\"Class proportions:\", class_proportions_val)\n",
    "\n",
    "print(\"TEST Dataset:\")\n",
    "print(\"Number of images:\", test_size)\n",
    "print(\"Number of classes:\", num_classes_test)\n",
    "print(\"Number of images from each class:\", class_counts_test)\n",
    "print(\"Class proportions:\", class_proportions_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
